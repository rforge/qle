% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/qsOpt.R
\name{qle}
\alias{qle}
\title{Simulated quasi-likelihood parameter estimation}
\usage{
qle(qsd, sim, ..., nsim, x0 = NULL, Sigma = NULL, global.opts = list(),
  local.opts = list(), method = c("qscoring", "bobyqa", "direct"),
  qscore.opts = list(), control = list(), errType = "kv", pl = 0L,
  cl = NULL, iseed = NULL, plot = FALSE)
}
\arguments{
\item{qsd}{object of class \code{\link{QLmodel}}}

\item{sim}{simulation function (see details)}

\item{...}{arguments passed to function `\code{sim}`}

\item{nsim}{optional, number of simulation replications at each new sample point,
`\code{qsd$nsim}` (default)}

\item{x0}{optional, numeric vector of starting parameters}

\item{Sigma}{optional, constant variance matrix estimate of statistics (see details)}

\item{global.opts}{options for global search phase}

\item{local.opts}{options for local search phase}

\item{method}{vector of names of local search methods}

\item{qscore.opts}{list of control arguments passed to \code{\link{qscoring}}}

\item{control}{list of control arguments passed to any of the routines defined in `\code{method}`}

\item{errType}{type of prediction variances (see details)}

\item{pl}{print level, use \code{pl}>0 to print intermediate output}

\item{cl}{cluster object, \code{NULL} (default), see \code{\link[parallel]{makeCluster}}}

\item{iseed}{integer seed, \code{NULL} (default) for no seeding of the RNG stream for each worker}

\item{plot}{if \code{TRUE}, plot newly sampled points (for 2D-parameter estimation problems only)}
}
\value{
List of the following objects:
	  \item{par}{ final parameter estimate}
	  \item{value}{ value of criterion function}
   \item{ctls}{ a data frame with values of stopping conditions}
   \item{qsd}{ final \code{\link{QLmodel}} object, including all sample points
				  and covariance models}
	  \item{cvm}{ CV fitted covariance models}
   \item{why}{ names of stopping conditions matched}
	  \item{minima}{ matrix of all local minima found so far}
	  \item{score}{ quasi-score or gradient of MD}
	  \item{convergence}{ logical, whether the iterates converged, see details} 	  

 Attributes: 	 
 \item{final}{ final minimization results of criterion function (see \code{\link{searchMinimizer}}) }
 
 \item{optInfo}{ a list:}
   \itemize{
   \item{x0:}{ starting vector (parameter)}
	  \item{W:}{ final weighting matrix for average approximation of variance matrix and
				 quasi-information matrix at \code{theta} for local sampling of new candidate points}
   \item{theta:}{ parameter corresponding to \code{W}} 
	  \item{last.global:}{ logical, whether last iteration sampled a point globally}
	  \item{minimized:}{ whether last minimization was successful}
	  \item{useCV:}{ logical, whether the CV approach was applied}
	  \item{method:}{ final search method applied}
   \item{nsim:}{ number of simulation replications at each point}
	  \item{iseed}{ the seed given by the user, see arguments}
 }
}
\description{
This is the main function using a simulated quasi-likelihood estimation (QLE) approach.
}
\details{
The function sequentially estimates the unknown model parameter. Basically, the user supplies a simulation function `\code{sim}`
 which must return a vector of summary statistics (as the outcome of model simulations) and expects a vector of parameters
 as its first argument. Further arguments can be passed by the `\code{\ldots}` ellipsis. The object
 `\code{qsd}` aggregates the type of variance matrix approximation, the data frame of observed and simulated data, the
 initial sample points and the covariance models of the involved statistics (see \code{\link{QLmodel}}). In addition, it defines
 the criterion function by `\code{qsd$criterion}`, which is either used to monitor the sampling process or minimized itself. The user
 also has the option to choose among different types of prediction variances: either "\code{kv}" (kriging variances), "\code{cv}"
 (cross-validation variances) or the maximum of both, by "\code{max}", are available.

 \subsection{Criterion functions}{  
 The QD criterion function follows the quasi-likelihood estimation principle (see vignette) and seeks a solution to the quasi-score
 equation. Besides, the Mahalanobis distance (MD) as an alternative (simulation-based) criterion function has a more direct
 interpretation. It can be seen as a (weighted or generalized) least squares criterion
 depending on the employed type of variance matrix approximation. For this reason, we support several types of variance matrix
 approximations. In particular, given `\code{Sigma}` and setting `\code{qsd$var.type}` equal to "\code{const}" treats `\code{Sigma}`
 as a constant estimate throughout the whole estimation procedure. Secondly, if `\code{Sigma}` is supplied and used as
 an average variance approximation (see \code{\link{covarTx}}), it is considered an initial variance matrix approximation and
 recomputed each time an approximate (local) minimizer of the criterion function is found. This is commonly known as an iterative update
 strategy of variance matrices in the context of GMM estimation. Opposed to this, setting `\code{qsd$var.type}` equal to
 "\code{kriging}" corresponds to continuously updating the variance matrix each time a new criterion function value is
 required at any point of the parameter space. In this way the algorithm can also be seen as a simulated version of a least squares
 method or even as a special case of a \emph{simulated method of moments} (see, e.g. [3]). Note that some input combinations
 concerning the variance approximation types are not applicable since the criterion "\code{qle}", which exploits the
 QD criterion function, does not use a constant variance at all. For this criterion the consistency is automatically checked for all
 roots found during the estimation procedure and stored in the data frame object `\code{minima}` where the best one is marked by a `*` and
 otherwise these are given without a consistency check. 
 }
      
 \subsection{Sampling new points}{  
 Our QLE approach dynamically switches from a \emph{local} to a \emph{global search phase} and vise versa for sampling new promising
 candidates for evaluation, that is, performing new simulations of the statistical model. Depending on the current value of the criterion
 function three different sampling criteria are used to select next evaluation points which aim on potentially improving the quasi-score
 or criterion function approximation. Values less than a user defined tolerance `\code{local.opts$ftol_abs}` trigger the local
 phase for sampling and searching. In this case it is assumed to have found a local minimizer such that it seems
 to be worth sampling in its local vicinity. Then local searches mostly try to improve on the current best parameter estimate.
 Either the next evaluation point is selected according to a weighted minimum-distance criterion (see [2] and the vignette),
 for the choice `\code{nextSample}` equal to "\code{score}", or by maximizing the weighted variance of the quasi-score vector in
 case `\code{nextSample}` is equal to "\code{var}". In all other cases, for example, if identifiable roots of the QS could not be found
 or the (numerical) convergence of the local solvers failed, the global phase of the algorithm is invoked and selects new potential
 candidates accross the whole search space based on a weighted selection criterion. This assigns large weights to candidates
 with low criterion function values and vise versa. During both phases the cycling between local and global candidates is
 controlled by the weights `\code{global.opts$weights}` and `\code{locals.opts$weights}`, respectively. (If the algorithm is within the 
 global phase at last iteration, then finally a global exhaustive search (if "\code{direct}" is part of the argument `\code{method}`)
 for the best minimizer is done.) Besides this, the smaller the weights the more the candidates tend to be globally selected and vice versa.
 Within the local phase, weights approaching one result in selecting candidates close to the current minimizer of the criterion
 function. Weights approximately zero maximize the minimum distance between candidates and previously sampled points and
 thus densely sample the search space almost everywhere if the algorithm is allowed to run infinitely. The choice of weights
 is somewhat ad hoc but may reflect the users preference on guiding the whole estimation more biased towards either a local
 or global search. In addition the local weights can be dynamically adjusted if `\code{useWeights}` is \code{FALSE}
 depending on the current progress of estimation. In this case the first weight given by `\code{locals.opts$weights}` is 
 used as a starting point for this kind of adjustment.   
 
 If any of the termination criteria is met, in conjunction with a neglectable value of the criterion function, we
 say that the algorithm successfully terminated and converged to a reasonable parameter estimate. In addition, we 
 can access the precision of the found estimator by a goodness-of-fit test (see \code{\link{qleTest}}). Also
 in case of multiple roots, stored in the matrix of found roots `\code{minima}`, the function
 \code{\link{checkMultRoot}} may be helpful to select the \emph{best} of these roots (see vignette). If we wish to improve the
 final estimate the algorithm allows for a simple warm start strategy though not yet as an fully automated procedure. The
 algorithm can be easily restarted based on the final result of the preceeding run. We only need to extract the object
 `\code{OPT$qsd}` as an input argument to function \code{\link{qle}} again.  
 }

 \subsection{Some notes}{   
	For a 2D parameter estimation problem the function can visualize the sampling and selection process, which
 requires an active 2D graphical device in advance. The function can also be run in an cluster environment
 using the `parallel` package. Make sure to export all functions to the cluster environment `\code{cl}` beforehand,
 loading required packages on each cluster node, which are used in the simulation function
 (see \code{\link[parallel]{clusterExport}} and \code{\link[parallel]{clusterApply}} in \code{parallel} package).
 If no cluster object is supplied, a local cluster is set up based on forking (under Linux) or as a socket connection
 for other OSs. One can also set an integer seed value `\code{iseed}` to initialize each worker, see \code{\link[parallel]{clusterSetRNGStream}},
 for reproducible results of estimation in case a local cluster is used, i.e. \code{cl=NULL} and option \code{mc.cores>1}. If
 using a prespecified cluster object \code{cl}, then the user is responsible for seeding whereas the seed can be stored
 in the return value as well, see attribute `\code{optInfo}$iseed`.     
 }

 The following controls `\code{local.opts}` for the local search phase are available:
  \itemize{
  \item{\code{ftol_rel}:}{ upper bound on relative change in criterion function values}
  \item{\code{lam_max}:}{ upper bound on the maximum eigenvalue of the generalized eigenvalue decomposition of
		the quasi-information matrix and estimated interpolation error (variance) of quasi-score.
 	This stops the main iteration sampling new locations following the idea that in this case
		the quasi-score interpolation error has dropped below the estimated precision at best measured by
		quasi-information matrix for `\code{global.opts$NmaxLam}` consecutive iterates.}
	 \item{\code{pmin}:}{ minimum required probability that a new random candidate sample falls inside the parameter
               space. Dropping below this value triggers a global phase sampling step. This might indicate
				  that the inverse of the quasi-information matrix does not sufficiently reflect the variance
				  of the current parameter estimate due to a sparse sample or the (hyper)box constraints of the
				  parameter space could be too restrictive.}
	 \item{\code{nsample}:}{ sampling size of candidate locations at the local phase}
	 \item{\code{weights}:}{ vector of weights, \eqn{0\leq\code{weights}\leq 1}, for local sampling}
	 \item{\code{useWeights}:} {logical, if \code{FALSE} (default), dynamically adjust the weights, see vignette}
 \item{\code{ftol_abs}:}{ upper bound on function criterion, values smaller than this trigger the local phase
					  following the reasoning that the algorithm has found an approximate root of the quasi-score
					  (or the gradient of the Mahalanobis distance).}
  \item{\code{eta}:}{ values for decrease and increase of the local weights, which is intended to faciliate convergence
		 while sampling new points more and more around the current best parameter estimate.} 				
  \item{\code{nfail}:}{ maximum number of consecutive failed iterations}
  \item{\code{nsucc}:}{ maximum number of consecutive successful iterations}
  \item{\code{nextSample}:}{ either "\code{score}" (default) or "\code{var}" (see details)} 
  }

 The following controls `\code{global.opts}` for the global search phase are available:   
	\itemize{
  \item{\code{stopval}:}{ stopping value for criterion function, if `\code{stopval>0}` then the main iteration terminates
				     as soon as the function value drops below. This might be preferable to a time consuming
					 sampling procedure if one whishes to simply minimize the criterion function or find a first
					 approximation to the unknown model parameter.}
  \item{\code{C_max}:}{ upper bound on the relative maximum quasi-score interpolation error. The algorithm terminates
					its value drops below after a number of `\code{global.opts$NmaxCV}` consecutive iterations.}
	 \item{\code{xtol_rel}:}{ relative change of found minimizer of the criterion function or root of quasi-score.}
	 \item{\code{maxiter}:}{ maximum allowed global phase iterations }
	 \item{\code{maxeval}:}{ maximum allowed global and local iterations }
	 \item{\code{sampleTol}:}{ minimum allowed distance between sampled locations at global phase}	
	 \item{\code{weights}:}{ vector of \eqn{\code{weights}>0} for global sampling}
  \item{\code{nsample}:}{ sampling size of candidate locations at the global phase}
  \item{\code{NmaxRel}:}{ maximum number of consecutive iterates for `\code{xtol_rel}`}
  \item{\code{NmaxCV}:}{ maximum number of consecutive iterates for `\code{C_max}`}
  \item{\code{NmaxSample}:}{ maximum number of consecutive iterates for `\code{sampleTol}`}
  \item{\code{NmaxLam}:}{ maximum number of consecutive iterates for `\code{local.opts$lam_max}` }
  \item{\code{Nmaxftol}:}{ maximum number of consecutive iterates for `\code{local.opts$ftol_rel}`}
 }
}
\examples{
\dontrun{
## Quasi-likelihood simulation based estimation
##
## 1. use criterion `qle` for estimation
## 2. then `mahal` as (generalized) least squares
library(qle)
data(normal)

options(mc.cores=8)

RNGkind("L'Ecuyer-CMRG")
set.seed(1356)

# one step minimization
# no sammpling
x0 <- c(2.5,1.5)
qscoring(qsd, x0, pl=10,verbose=TRUE)

# alternatively use minimization by `nloptr`
searchMinimizer(x0, qsd, method = c("bobyqa"), verbose=TRUE)

# QLE approach:
OPT <- qle(qsd,qsd$sim,nsim=100,
		global.opts=list("maxeval"=50),
		local.opts=list("lam_max"=1e-3,"weights"=0.5),
		pl=3)

# solution (with  details)
print(OPT,pl=3)

# prepare for a restart 
qsd2 <- OPT$qsd

# and do a pure global search by `ftol_abs=0` 
# sample additional (globally selected) points
# for evaluation by selection criterion `var`
GL <- qle(qsd2, qsd$sim,nsim=100,		
		global.opts = list( "maxiter"=10, "stopval"=0),
		local.opts = list("nextSample"="var","ftol_abs"=0),
		pl = 3)


# Use a least squares approach 
qsd$criterion <- "mahal"
MA <- qle(qsd, qsd$sim, method = c("lbfgs","bobyqa","direct"), 
		global.opts = list("maxiter" = 10, "maxeval"=25), pl = 3)

# results (short)
MA	
# use pl=1,2,3 for more information	
print(MA,pl=3)
}

}
\seealso{
\code{\link{mahalDist}}, \code{\link{quasiDeviance}}
}
\author{
M. Baaske
}
